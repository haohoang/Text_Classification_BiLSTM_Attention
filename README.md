# Text_Classification_BiLSTM_Attention
PhÃ¢n  loáº¡i  vÄƒn báº£n tiáº¿ng  Viá»‡t dá»±a trÃªn há»c sÃ¢u
1. Dá»¯ liá»‡u
- Tiáº¿ng Viá»‡t
- 10 Chá»§ Ä‘á» 
2. Tiá»n xá»­ lÃ½
- BÆ°á»›c xá»­ lÃ½: tÃ¡ch tá»«, loáº¡i bá» stopwords, kÃ½ tá»± Ä‘áº·c biá»‡t
- Láº¥y vector nhÃºng cá»§a tá»« (Word2Vec)
3. MÃ´ hÃ¬nh
- Thay vÃ¬ cho trá»±c tiáº¿p vector pre-train cá»§a tá»« lÃ m Ä‘áº§u vÃ o cá»§a máº¡ng thÃ¬ vector cá»§a tá»« sáº½ Ä‘Æ°á»£c tÃ­nh báº±ng trung bÃ¬nh cá»™ng vector cá»§a tá»« Ä‘á»©ng liá»n trÆ°á»›c tá»« Ä‘Ã³, vector cá»§a tá»« Ä‘Ã³ vÃ  vectÆ¡ cá»§a tá»« Ä‘á»©ng liá»n sau tá»« Ä‘Ã³.
- Sá»­ dá»¥ng máº¡ng LSTM hai chiá»u Ä‘á»ƒ há»c cÃ¡c Ä‘áº·c trÆ°ng cá»§a vÄƒn báº£n vÃ¬ Ã½ nghÄ©a cá»§a má»™t tá»« khÃ´ng chá»‰ liÃªn quan Ä‘áº¿n nhá»¯ng nhá»¯ng tá»« Ä‘á»©ng trÆ°á»›c nÃ³ mÃ  cÃ²n cÃ³ cáº£ tá»« Ä‘á»©ng sau nÃ³.
- Hai tráº¡ng thÃ¡i áº©n cá»§a má»—i chiá»u LSTM cá»§a tá»« xi sáº½ Ä‘Æ°á»£c káº¿t há»£p láº¡i (hi) lÃ m Ä‘áº§u vÃ o cho seft-attention Ä‘á»ƒ tÃ­nh trá»ng sá»‘ ï¡i cho nÃ³.
- Trá»ng sá»‘ ï¡i Ä‘Æ°á»£c tÃ­nh báº±ng softmax(hi, V) vá»›i V lÃ  vector biá»ƒu diá»…n cho category, sáº½ Ä‘Æ°á»£c há»c trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. Káº¿t há»£p cÃ¡c trá»ng sá»‘ ï¡i vÃ  cÃ¡c tráº¡ng thÃ¡i áº©n hi Ä‘Æ°á»£c vector Ä‘áº·c trÆ°ng cÃ³ trá»ng sá»‘ ha. 
- Biá»ƒu diá»…n vÄƒn báº£n cuá»‘i cÃ¹ng s chÃ­nh lÃ  káº¿t há»£p cá»§a ha vÃ  hai tráº¡ng thÃ¡i áº©n cuá»‘i cÃ¹ng cá»§a hai máº¡ng LSTM.
- Cuá»‘i cÃ¹ng cho s lÃ m Ä‘áº§u vÃ o má»™t táº§ng káº¿t ná»‘i Ä‘áº§y Ä‘á»§ cÃ³ sá»­ dá»¥ng dropout (nháº±m trÃ¡nh viá»‡c overfitting) cÃ³ sá»‘ Ä‘áº§u ra báº±ng sá»‘ thá»ƒ loáº¡i. Ãp dá»¥ng softmax cho Ä‘áº§u ra cuá»‘i Ä‘á»ƒ dá»± Ä‘oÃ¡n thá»ƒ loáº¡i cá»§a vÄƒn báº£n.
![Picture1](https://user-images.githubusercontent.com/50910747/129135641-a9557c5b-a034-4db0-ad02-1ee23e9a2c28.png)

4. HÃ m má»¥c tiÃªu
HÃ m má»¥c tiÃªu lÃ  cross-entropy:
ğ¿ = âˆ‘1_(ğ‘–=1)^ğ‘‡â–’logâ¡ã€–ğ‘(ğ‘¦_ğ‘– â”¤|  ğ‘‹_ğ‘–, ğœƒ)+ ğœ†â€–ğœƒâ€–_2^2 ã€— 
Vá»›i (ğ‘‹_ğ‘–, ğ‘¦_ğ‘–) lÃ  cÃ¡c cáº·p vÃ­ dá»¥ há»c, T lÃ  sá»‘ vÃ­ dá»¥ há»c, ğœƒ lÃ  táº¥t cáº£ cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh, ğœ† lÃ  tham sá»‘ cá»§a thÃ nh pháº§n regularization. CÃ¡c trá»ng sá»‘ Ä‘Æ°á»£c cáº­p nháº­t báº±ng giáº£i thuáº­t Adam.

5. Tham kháº£o
[1] Du, Changshun, and Lei Huang. "Text classification research with attention-based recurrent neural networks." International Journal of Computers Communications & Control 13.1 (2018): 50-61

